# Internship Tracker + Scraper

This project is your personal internship/job tracking dashboard plus an automated scraper that fetches internship postings from trusted companies (including LinkedIn) and emails them to you.

---

## ğŸ“¦ Directory Structure

internship-tracker/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ server.js
â”‚ â”œâ”€â”€ scraper/
â”‚ â”‚ â”œâ”€â”€ companyList.json
â”‚ â”‚ â”œâ”€â”€ scraper.js
â”‚ â”‚ â””â”€â”€ emailer.js
â”‚ â”œâ”€â”€ package.json
â”‚ â””â”€â”€ prisma/
â”‚ â””â”€â”€ schema.prisma
â”œâ”€â”€ app/ # Next.js frontend (App Router)
â”‚ â”œâ”€â”€ page.tsx
â”‚ â”œâ”€â”€ add-job/
â”‚ â”‚ â””â”€â”€ page.tsx
â”‚ â”œâ”€â”€ edit-job/
â”‚ â”‚ â””â”€â”€ [id]/page.tsx
â”‚ â”œâ”€â”€ scraper/
â”‚ â”‚ â””â”€â”€ page.tsx # optional viewer of scraped jobs
â”‚ â””â”€â”€ globals.css
â”œâ”€â”€ package.json # frontend package
â””â”€â”€ README.md


---

## ğŸ›  Prerequisites

- Node.js v18+  
- A Gmail account (or other SMTP) for sending email (you may need to allow â€œapp passwordsâ€ or enable SMTP)  
- Internet access (for scraping)  
- For LinkedIn scraping, you may need authentication or a proxy (LinkedIn is more restrictive than Indeed).

---

## ğŸ”§ Setup & Configuration

### Backend Setup

1. Navigate into backend folder:

   ```bash
   cd backend

2. Edit package.json to include:
    {
        "type": "module",
        ...
    }

3. Install dependencies:
    npm install express cors @prisma/client prisma node-cron nodemailer node-fetch cheerio

4. Setup Prisma schema (in backend/prisma/schema.prisma) and run:
    npx prisma migrate dev --name init

5. Create a .env in backend/ with email credentials:
    MAIL_USER=your.email@gmail.com
    MAIL_PASS=your-email-app-password

### Frontend Setup

In the root of your project (the folder containing package.json for frontend):
    npm install
Make sure that your app/layout.tsx imports globals.css.

### ğŸš€ Running the App

In the root of your project (the folder containing package.json for frontend):

1. Start backend + scraper

   ```bash
   cd backend
If you added a cron schedule inside server.js (e.g. to run scraping every few hours), the scraper will run automatically.

Alternatively, you can manually run:
    node scraper/scraper.js
to trigger a scrape + email immediately.

2. Start frontend:
    npm run dev

Open your browser at http://localhost:3000.
